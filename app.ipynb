{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd856919-31fb-40c4-938a-f3b2046341cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "token =  \"Your Token Here\"\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "#client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token)\n",
    ")\n",
    "def perform_analysis(text, chars=100):\n",
    "    # 'gpt-4o-mini' is free and excellent for this task\n",
    "    model_name = \"gpt-4o-mini\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data analyst.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analyze this text for Sentiment, Crux, and Summary({chars} characters): {text} in raw json format only\"}\n",
    "        ],\n",
    "        model=model_name\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6788e383-0bb0-4d2e-865a-8fc494580082",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = perform_analysis(\"Priya, I saw your campaign proposal. Honestly, itâ€™s just not good enough. I expected more from you. You need to improve.\", 1)\n",
    "\n",
    "json_data = ans.replace('```json', '').replace('```', '')\n",
    "json_data = json_data.replace(\"\\n\", \"\")\n",
    "\n",
    "json_file = open(\"temp_data.json\", \"w\")\n",
    "json_file.write(json_data)\n",
    "json_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e68a1889-54b4-4f54-9a60-58ca95c9a1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sentiment': 'Negative', 'Crux': 'The proposal is disappointing and requires improvement.', 'Summary': 'Negative feedback on campaign proposal.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"temp_data.json\", 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "print(eval(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d99895db-8acb-45b2-a7b5-469f7b70cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain-openai openai\n",
    "#!pip install langchain-ollama\n",
    "\n",
    "# from langchain_ollama import ChatOllama\n",
    "# from langchain_classic import LLMChain\n",
    "# from langchain_classic.prompts import ChatPromptTemplate\n",
    "# from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_classic.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "# from langchain_classic.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20a3fcb-aa99-4aee-982a-6c292ce21052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Initialize LLM\n",
    "# llm = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8712d284-6beb-41ba-857f-2ab63fd733a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Define the Multi-Task Prompt\n",
    "# prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "# Analyze the following text segment and provide:\n",
    "# - SENTIMENT: (Positive, Negative, or Neutral)\n",
    "# - THE CRUX: (The most important takeaway)\n",
    "# - SUMMARY: (A brief 2-sentence overview)\n",
    "\n",
    "# TEXT:\n",
    "# {text}\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd24036f-80ee-444c-9393-395fa62c1263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_chain = prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "882c9e12-23eb-419f-a17b-a8423f80388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Define the REDUCE Prompt (Final consolidation)\n",
    "# reduce_template = \"\"\"\n",
    "# The following are individual analyses from different parts of a long document:\n",
    "# {analyses}\n",
    "\n",
    "# Please provide a FINAL GLOBAL ANALYSIS:\n",
    "# 1. OVERALL SENTIMENT: (Aggregate the tone across all parts)\n",
    "# 2. THE MASTER CRUX: (Synthesize the most critical points into one core message)\n",
    "# 3. EXECUTIVE SUMMARY: (A concise paragraph summarizing the entire document)\n",
    "# \"\"\"\n",
    "# reduce_prompt = ChatPromptTemplate.from_template(reduce_template)\n",
    "# reduce_chain = reduce_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1213e33f-7f1f-4ca4-9654-0909c7fb816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Processing Function\n",
    "# def process_full_dataset(long_text):\n",
    "#     # Split text into chunks to avoid token limits\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=400)\n",
    "#     chunks = text_splitter.split_text(long_text)\n",
    "    \n",
    "#     # Map: Process each chunk\n",
    "#     print(f\"Processing {len(chunks)} chunks...\")\n",
    "#     chunk_analyses = []\n",
    "#     for chunk in chunks:\n",
    "#         res = map_chain.invoke({\"text\": chunk})\n",
    "#         chunk_analyses.append(res)\n",
    "    \n",
    "#     # Reduce: Combine all analyses\n",
    "#     combined_analyses = \"\\n\\n\".join(chunk_analyses)\n",
    "#     final_output = reduce_chain.invoke({\"analyses\": combined_analyses})\n",
    "    \n",
    "#     return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90f6377c-2d27-49ea-984a-2c3e8a06518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_analyze = \"Your very long text here...\"\n",
    "# result = process_full_dataset(text_to_analyze)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78d3d459-2f34-4247-a607-e6755449f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U google-genai\n",
    "#!pip install azure-ai-inference\n",
    "#!pip install azure-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0ce20fb-b3e9-426e-b4f8-b0f7eeb7fa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Sentiment:** The sentiment of the text is negative. It expresses dissatisfaction with the service received.\\n\\n**Crux:** The central point of the text is a complaint regarding the poor quality of service.\\n\\n**Summary:** The text conveys a negative experience, highlighting that the service provided was very unsatisfactory.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_analysis(\"The Service was Very Bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06d581bc-db25-4e1e-9fe7-01692526cede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec1dec-59b0-40ca-8c79-2c7259d64155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbd33b-f408-46a2-a687-0c20cfe6380a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
